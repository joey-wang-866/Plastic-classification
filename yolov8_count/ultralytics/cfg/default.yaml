task: detect  # (str) YOLO任务，即detect（检测），segment（分割），classify（分类），pose（姿态）
mode: train  # (str) YOLO模式，即train（训练），val（验证），predict（预测），export（导出），track（跟踪），benchmark（基准测试）

# 训练设置 -------------------------------------------------------------------------------------------------------
model:  # (str, optional) 模型文件路径，例如yolov8n.pt，yolov8n.yaml
data:  # (str, optional) 数据文件路径，例如coco128.yaml
epochs: 100  # (int) 训练的轮数
patience: 50  # (int) 早停机制，等待观察不到改善的轮数以提前停止训练
batch: 8  # (int) 每批处理的图像数（-1表示自动批处理）
imgsz: 640  # (int | list) 输入图像的大小，对于训练和验证模式为int，对于预测和导出模式为list[w,h]
save: True  # (bool) 保存训练检查点和预测结果
save_period: -1 # (int) 每x轮保存一次检查点（如果<1则禁用）
cache: False  # (bool) True/ram，disk或False。使用缓存进行数据加载
device:   # (int | str | list, optional) 运行设备，例如cuda device=0或device=0,1,2,3或device=cpu
workers: 8  # (int) 数据加载的工作线程数（每个RANK如果DDP）
project:  # (str, optional) 项目名称
name:  # (str, optional) 实验名称，结果保存在'project/name'目录中
exist_ok: False  # (bool) 是否覆盖现有实验
pretrained: True  # (bool | str) 是否使用预训练模型（bool）或要加载权重的模型（str）
optimizer: auto  # (str) 要使用的优化器，choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]
verbose: True  # (bool) 是否打印详细输出
seed: 0  # (int) 用于可重现性的随机种子
deterministic: True  # (bool) 是否启用确定性模式
single_cls: False  # (bool) 将多类数据训练为单类
rect: False  # (bool) 如果mode='train'则进行矩形训练，如果mode='val'则进行矩形验证
cos_lr: False  # (bool) 使用余弦学习率调度程序
close_mosaic: 10  # (int) 在最后几轮禁用马赛克增强（0表示禁用）
resume: False  # (bool) 从上次检查点恢复训练
amp: True  # (bool) 自动混合精度（AMP）训练，choices=[True, False]，True运行AMP检查
fraction: 1.0  # (float) 要训练的数据集分数（默认为1.0，训练集中的所有图像）
profile: False  # (bool) 在训练期间为记录器启用ONNX和TensorRT速度
freeze: None  # (int | list, optional) 冻结前n层，或在训练期间冻结层索引的列表

# 分割
overlap_mask: True  # (bool) 训练期间掩码应重叠（仅适用于分割训练）
mask_ratio: 4  # (int) 掩码下采样比率（仅适用于分割训练）
# 分类
dropout: 0.0  # (float) 使用dropout正则化（仅适用于分类训练）

# 验证/测试设置 ----------------------------------------------------------------------------------------------------
val: True  # (bool) 在训练期间进行验证/测试
split: val  # (str) 用于验证的数据集拆分，例如'val'，'test'或'train'
save_json: False  # (bool) 将结果保存到JSON文件
save_hybrid: False  # (bool) 保存标签的混合版本（标签+额外预测）
conf:  # (float, optional) 用于检测的对象置信度阈值（默认为0.25预测，0.001验证）
iou: 0.7  # (float) 非最大抑制（NMS）的交并比（IoU）阈值
max_det: 300  # (int) 每张图像的最大检测数
half: False  # (bool) 使用半精度（FP16）
dnn: False  # (bool) 使用OpenCV DNN进行ONNX推断
plots: True  # (bool) 在训练/验证期间保存绘图和图像

# 预测设置 -----------------------------------------------------------------------------------------------------
source:  # (str, optional) 图像或视频的源目录
vid_stride: 1  # (int) 视频帧速率跨度
stream_buffer: False  # (bool) 缓冲所有流式帧（True）或返回最近的帧（False）
visualize: False  # (bool) 可视化模型特征
augment: False  # (bool) 对预测源应用图像增强
agnostic_nms: False  # (bool) 类别不可知的NMS
classes:  # (int | list[int], optional) 按类别过滤结果，例如classes=0，或classes=[0,2,3]
retina_masks: False  # (bool) 使用高分辨率分割掩码

# 可视化设置 ---------------------------------------------------------------------------------------------------
show: False  # (bool) 如果环境允许，显示预测的图像和视频
save_frames: False  # (bool) 保存预测的单个视频帧
save_txt: False  # (bool) 将结果保存为.txt文件
save_conf: False  # (bool) 保存带有置信度得分的结果
save_crop: False  # (bool) 保存带有结果的裁剪图像
show_labels: True  # (bool) 显示预测标签，例如'person'
show_conf: True  # (bool) 显示预测置信度，例如'0.99'
show_boxes: True  # (bool) 显示预测框
line_width:   # (int, optional) 边界框的线宽。如果为None，则缩放到图像大小


# 导出设置 ------------------------------------------------------------------------------------------------------
format: torchscript  # (str) 导出格式，选项请参见https://docs.ultralytics.com/modes/export/#export-formats
keras: False  # (bool) 使用Keras
optimize: False  # (bool) TorchScript: 优化为移动设备
int8: False  # (bool) CoreML/TF INT8 量化
dynamic: False  # (bool) ONNX/TF/TensorRT: 动态轴
simplify: False  # (bool) ONNX: 简化模型
opset:  # (int, optional) ONNX: opset 版本
workspace: 4  # (int) TensorRT: 工作空间大小（GB）
nms: False  # (bool) CoreML: 添加NMS

# 超参数 ------------------------------------------------------------------------------------------------------
lr0: 0.01  # (float) 初始学习率（例如SGD=1E-2，Adam=1E-3）
lrf: 0.01  # (float) 最终学习率（lr0 * lrf）
momentum: 0.937  # (float) SGD动量/Adam beta1
weight_decay: 0.0005  # (float) 优化器权重衰减5e-4
warmup_epochs: 3.0  # (float) 预热轮数（可以是小数）
warmup_momentum: 0.8  # (float) 预热初始动量
warmup_bias_lr: 0.1  # (float) 预热初始偏置学习率
box: 7.5  # (float) 目标框损失增益
cls: 0.5  # (float) 类别损失增益（与像素成比例）
dfl: 1.5  # (float) dfl损失增益
pose: 12.0  # (float) 姿态损失增益
kobj: 1.0  # (float) 关键点obj损失增益
label_smoothing: 0.0  # (float) 标签平滑（分数）
nbs: 64  # (int) 名义批次大小
hsv_h: 0.015  # (float) 图像HSV-Hue增强（分数）
hsv_s: 0.7  # (float) 图像HSV-Saturation增强（分数）
hsv_v: 0.4  # (float) 图像HSV-Value增强（分数）
degrees: 0.0  # (float) 图像旋转（+/- deg）
translate: 0.1  # (float) 图像平移（+/- 分数）
scale: 0.5  # (float) 图像缩放（+/- gain）
shear: 0.0  # (float) 图像剪切（+/- deg）
perspective: 0.0  # (float) 图像透视（+/- 分数），范围0-0.001
flipud: 0.0  # (float) 图像上下翻转（概率）
fliplr: 0.5  # (float) 图像左右翻转（概率）
mosaic: 1.0  # (float) 图像马赛克（概率）
mixup: 0.0  # (float) 图像混合（概率）
copy_paste: 0.0  # (float) 分割复制-粘贴（概率）

# 自定义config.yaml ---------------------------------------------------------------------------------------------------
cfg:  # (str, optional) 用于覆盖defaults.yaml的配置

# 追踪器设置 ------------------------------------------------------------------------------------------------------
tracker: botsort.yaml  # (str) 追踪器类型，选项=[botsort.yaml, bytetrack.yaml]
